We have reviewed the concepts, the particular theories and development made in history, and the current usage of the treatment in the field of artificial intelligence and by extension to the modern machine learning theory. While there are much to be desired, it is imperative to note that we did not do a thorough overview, but the general theoretical interest. 

With that, comes evaluation of the classical stance. Even though the classical theory can be seen as quite advanced and matured, in fact, it is not. Rather, it is endowed in the world of mathematics and empiricalism, for its advancements and development as present. Furthermore, which is one of the factor that inflicts the status of \textit{naive} onto the classical treatment, is the overall no coherence structure - given how much and how rapid the changes have been - of the establishment, both practical-wise and theory-wise. Science itself, particularly, also has this problem. Other than that, there is also the fact that the current framework of theoretical artificial intelligence is not matured enough to take on various new questions and problems that are detrimental to their operation and mechanism. If one was to say, then they would be saying that while we dream of AGI (Artificial General Intelligence), we have no tools capable of reaching it aside from the dreams come true of wishes. 

It is again, not superficially mentioned to downplay the impact and role of classical theory in the development and conceptualization of artificial constructs. It is, however, inadequate of the present, insufficient for the future, and inoperable in practice. We then, is inclined to accept and continue on toward a newer approach. 

The following part of several chapters will be dedicated specifically to allow for the perhaps new formalism and theory to grow. In such, we will tackle those problems that the old scientist and researchers failed, those problems that was created from their insight (and failure), and lessons from successes. Fortunately for us, those are plenty, and we have to look not too further from the starting point to see the beacon where we will proceed. 

\chapter{General principles}


For much of the history, as well as the current conception of artificial intelligence designing, the design and implementation of AI has been influenced into the four main paradigm, as mentioned in Norvig's Artificial Intelligence. A modern approach (2011). Alternatively, it also follows the more general view toward either looking specifically at the structural components of any specimen of intelligence (human neurons and animal's), or \textit{neurological approach}, also called \textit{connectionism}; and those that follow the view of universal rationalism, capturing the essence behavioural constructs, and basing AI constructions on such universal justification, the \textit{symbolic AI} approach. While those theories can be said to eventually be useful and perhaps, more groundbreaking than not, they are not so much desirable, as they are also very well-being specialized, unscalable, and was stuck in the paradigm of the more simpler tasks. In fact, whilst NLP, the chatbot that is prominent in the later date of the 2010s was hailed to be the epitome of development in AI (which indeed, perhaps it is), the issues with, for example, \textit{common sense knowledge} is still present, and any attempt in fixing it often resulted in either the rough, uncertain and naive mimic of the 'real thing', or fails miserably. In one way or another of such, we can say that the current AI theory has no \textit{framework}. Or at least a manageable one. 

It is then of our interest to put up at least a view of what should be, and what can be said of artificial intelligence as a framework, a system for theories, and the principles in which one can say about the core essence of artificial intelligence, given an interpretation. In said following sections, we would allow ourselves to tread the thin line, and lay out the foundation of what to develop to a full-fledged artificial intelligence theory. 

What should be expected of this outline? Not so much. The ultimate goal here is to formalize the principles, the working mechanism, the designing compass in which developments might ensue of a later date. Settle on matters that of said digression, will influence how the entire framework is formed, from the macroscopic view to the microscopic design elements, the point of view of the system, and more on the treatment of such system in certainty. Or probabilistically, which you can choose. In fact, the issues between determinism and uncertainty (probability interpretation) will also be touched upon, forgoes the huge amounts of works on two said interpretations ambiguous as it is possible to be. 
\section{Defining artificial intelligence}
There are many ways to define artificial intelligence, either by the phenomenological one, or by the presumptuous, universal-assumed way of logicians in the old way. However, our definition, or at least mechanism of working on artificial intelligence, should be by then very different, as to not stumble upon the mistake of overestimating our predicate, and neglect the hardness of the problem itself.

What is then called AI, in our view? We treat AI as rather a more general system. First, we digress on the term \textbf{artificial}. We have talked about this in previous chapters, but, for the moment, it is perhaps better to reformulate it. A construct, object, subject $A$ is called \textit{artificial}, if it fits the following rough conceptual definition. 
\begin{definition}[Artificial]
    We say an object $A$ is artificial only if it is not natural, or rather, it is \textit{intentionally created} by meaning intentions, and not the general evolution of states, the natural interaction of the law of nature, or the natural transformation of biology.
\end{definition}
By such definition, artificial is then a quality to be separated from \textit{natural intelligence} - of naturally made intelligent vessels or construct, existed because of natural, biological evolution and advancements by itself. A construct, then, is the main interest of our study. What about intelligence then, one might ask? The truth is, we don't know. We know roughly that intelligence is the exhibition of rationalism, the actions and demonstration of perhaps consciousness, of thinking. However, we have no way to define operationally, formally, and if not, conceptually sound of such aspect of intelligence. Let's assume we don't know. Then artificial intelligence is especially the realization and the discovery of intelligence itself. This is pretty much universal as we can get, out of the existing structure and predicament. Overall, the \textit{universal argument} that would be utilized in developing our conceptual shell of artificial intelligence, shall not be too restrictive as for the universality of formal logic, for the world unable to be fully realized in formalism terms. We are now ready for a conceptual definition of artificial intelligence. 
\begin{definition}[Artificial intelligence]
    A \textbf{construct} $U$, subjected to a system $S$ is called \textbf{artificial intelligence} if it satisfies the condition of being artificial, whilst also satisfies a given criterion set of being autonomous, dynamic, and overall general. It is such that will give rise to \textit{intelligence construct}. 
\end{definition}

While it is dubious, we will further develop those points made above. However, we might as well want to justify the first point in all - the cogency of the intelligence criterion. 
\subsection{Intelligence criterion}
We mentioned the notion of the criterion of intelligence. However, what should we define it? How should we know to even evaluate it, is a very hard question even that we did not (or unable to) fully realize yet, then what we want to do with it? This question is where a lot of things in the artificial intelligence research was based upon. For example, the (Total) Turing Test in which outlines possible outlook for intelligence, for capabilities that then defines the fields in which we are having nowadays, for example, computer vision for the capability of visual perception, natural language processing (NLP) for the capacity of language, and more. We also have various conceptual criterions in which people have been suggesting about the model of the intelligent being, for example, various set of criterions that outlines and includes even consciousness, some suggest behavioural conditions, some goes for the exhibition of \textit{chain of thoughts}, and some even goes further than that, which is perhaps irrelevant aside from mentioned for example. Overall, it is perhaps a mess. 

We still do not know what to come of criteria, or rather, in the quest of producing intelligence, we base ourselves onto it too much. As a species capable of intelligence and more sophisticated notion, we have the basis, and the advantage of being able to examine ourselves. By that, eventually, as the highest example of intelligent being, we use ourselves as standard, for examine, psychology, neurological behaviourism, neuroscience, applied onto the quest of going for artificial intelligence. Hence, there exists the total Turing test, and there exists the conflicts between various definitions and criterion of artificial intelligence. A mistake perhaps has been made, doubtfully so that one did not realize of such. While it is said that AI researcher has been working on, or at least researching on the general notion of artificial intelligence principles, it is, in fact, not so much of a principle, as we did not realize yet that what we are doing is still the act of mimicking ourselves - creating a plane by replicating a bird. By phenomenologically absorb and construct architectures, models on the higher-level surface of what artificial intelligence constitute, the deeper construct is still non-existent. By copying the apparent capabilities of human and related intelligence being, biological rather than not, the core of which those behaviours occur, and facilitate the organs and observations made is perhaps, manifested. Ironically, while being too strict, wrongfully abhorrent to the fallacy of themselves, and too resistant to changes, symbolic approach got one of the right thing. If there exists intelligence, then it must be \textit{universal by virtue}. That is, you cannot argue that alien from another universe is not intelligent, because they do not satisfy one of the criteria of the Turing test, just because such notion does not exist in such universe. 
\subsection{ The should not of defining AI}
Personally, I don't think we should, or we could define artificial intelligence, at least of this particular stage that we are in. Philosophically, being an armchair philosopher would not help in pursuing such notion, yet again because we are arguing on the basis of our own existence, and not the subject's matter viewpoint. There are problems related to it, also, of such that the mind and consciousness is arguably debatable in every given sense, of which no one seems to agree on the mundane notion that intelligence and consciousness come from chemical and the weird 'quantum effect' that would be then believed to be. And, truth to be told, we are not even endorsing such direction. In actuality, we don't even know what is intelligent, and also don't even know what can be of artificially made rather than matching mathematics. 

On the flip side, computationally and neuroscientifically, the lack of formal treatment and overall encompassing knowledge conjunctions plague the construction and foremost attempt to do anything, simply because too many things have been said yet none can unify them together. Such is also to say different directions and different methodologies being conducted, yet they are so distinctively separated to be unable to conform one to another, despite them taking on the same object. Furthermore, there are a lot of assumptions given in computational theory, and the overall application thereof. As for anything, assumptions can be broken, and reinforced, for whatever it is being inconsistent as a virtue. 

It is wise to remember that, for now with neuroscience being not advanced enough and in a perhaps different direction from what can be seen, while certainly for empirical science we can utilize neuroscience's knowledge, we should not take in the philosophical arguments and 'idea', including computational theory of mind. For empirical neuroscience, it is also not the fully-encompassing field that observe the brain from every angle, and observe consciousness of everything if ever, at least of the present. And, for the \textit{philosophical} and idealistic view, only one thing can be said about such being "the lines on the map is made up". 
\subsection{Deferences in approach?}
So, how should we approach this particular problem where one wants to create more than just logic in disguise, but also computational in nature, or else that no one can predict? Well, it is to generalize them . Simply speak, we do not go for the AI itself, but what can then constitute it. Granted, it is not similar to going blindfolded, or any kind of predisposition that protest the usage of the term and outlook on AI simply because perhaps of the impression above that we do not know what it is, hence no need for pursuing on such narrow road. But rather, to extract the fundamental facilities, concept, objects that in conjunction of knowledge that can be brought up or newly constructed, that is relevant of interest. And starting from ground zero with the modesty of assuming none and bias to minimum. 
\begin{enumerate}[itemsep=1pt,topsep=0.5pt]
    \item We do not create artificial intelligence. We create and investigate the \textit{facilities}, the \textit{theory} of which structures and objects can be utilized to create the framework that is not intelligent, yet encompass more and might be able to give rise to intelligence. That is, for example, if we are to say that artificial intelligence can be constructed on a machine, then what can be said of the theory of machine? What is machine? What is the model for machine, and our understanding of such? What are machines that do not bear any similarity to the skewed vision of what is intelligent? And so is computer and its principle, and how we actually, formally, operate it? More so, we construct the subjects. The intelligent comes afterward. \footnote{ It also can be considered loosely as to focus on the chaotic behaviours and the role of \textbf{percolation} plus \textbf{emergence}, rather than, well, specific construction. But a blend of both that and descriptive criteria is objectively better, rather than relying on the sole factor of randomness.}
    \item We do not, consequently, gauge intelligence as per metric or in terms of the skewed test that one can take, or metric that one get the $R$-value and so forth. It is rather somewhat baseless in such regard. 
    \item We stand on the assumption of \textit{constructiveness} - there exists the \textit{absolute minimum} of any given object that can be the basis for more advanced concept and construction. Not regarding such constructiveness often gives us headache in co-joining different constructs and ideas together, or simply interpreting machines and constructions of their characteristics and properties rather than just 'somewhat weird trick'. This is more in line of what would be considered a more computer-specific property, however, it is perhaps rather universal in consideration of modelling. 
    \item No model is perfect, if we ever create one. 
    \item We regard artificial intelligence to be consisted of two main things: the \textbf{facilities} that support its existence, and the \textbf{process} that support the subject matter that is examined. By this, then, instead of for example, thinking that intelligence only exhibits in subjects that have the learning property. Then we go on the reverse. What would happen to any given subject, that has something even remotely similar to learning, without considering the case of "if it can learn then it is intelligent" and of what capability? That is, to consider the action to be components itself, and not 'requirement'?
\end{enumerate}
Overall, without stating more for out-of-scope reason (I do not intend for this note to go further into such discussion), we are trying to \textit{construct and investigate} the formal foundational knowledge first, before even can utilize it to construct a generalized construct that encompass what is not intelligent, and what is then intelligent. Then, construct it with assumptions and constructiveness, plus the realization of both the building, and the lifetime of such building by itself. With this, perhaps we can then continue what was left behind, of what we might want to do and upgrade. 
\relax 
\providecommand*{\memsetcounter}[2]{}
\nicematrix@redefine@check@rerun 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{Contents}{2}{section*.1}\protected@file@percent }
\citation{ANDRILLI20101}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{8}{section*.2}\protected@file@percent }
\citation{10.5555/2371238}
\citation{10.5555/2371238}
\citation{purves_neuroscience_2004}
\citation{10.5555/50066}
\citation{10.5555/50066}
\citation{belkin_reconciling_2019}
\citation{nakkiran_deep_2019}
\@input{content/introduction.aux}
\@input{content/chapter1.aux}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Preliminary}{29}{part.1}\protected@file@percent }
\@input{content/math/mathc1.aux}
\@input{content/math/mathc2.aux}
\@input{content/math/mathc3.aux}
\@input{content/math/mathc4.aux}
\@input{content/math/mathc5.aux}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Theory}{87}{part.2}\protected@file@percent }
\@input{content/chapter2.aux}
\@input{content/chapter4.aux}
\@input{content/chapter5.aux}
\@input{content/theory_main/chaptert1.aux}
\@input{content/theory_main/chaptert2.aux}
\@writefile{toc}{\contentsline {part}{III\hspace  {1em}Drafts}{189}{part.3}\protected@file@percent }
\@input{content/draft/c1_research.aux}
\@input{content/draft/c2_research.aux}
\@writefile{toc}{\contentsline {part}{IV\hspace  {1em}Appendix}{231}{part.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Index}{233}{section*.100}\protected@file@percent }
\citation{10.5555/2721661}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{List of transfer functions}{235}{chapter*.101}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Classical transfer functions}{235}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hard limit (\texttt  {hardlim[x]})}{235}{subsection*.103}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The typical hard limit transfer function with fixed $a$, and fixed range for $x$ in $[0,1]$.}}{235}{figure.caption.104}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The typical hard limit transfer function with variable inhibition $a$, and fixed range for $x$ in $[0,1]$.}}{236}{figure.caption.105}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Symmetric hard limit (\texttt  {hradlims[x]})}{236}{subsection*.106}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Linear family (\texttt  {satlin[x]}, \texttt  {satlins[x]}, \texttt  {purelin[x]})}{236}{subsection*.108}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The typical symmetric hard limit transfer function with static inhibition $a$, and fixed range for $x$ in $[-1,+1]$. As specified, this is the normal-extended range.}}{237}{figure.caption.107}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The saturating linear with linear region of $[0,1]$. A smoother variation would be something like sigmoidal functions, that is.}}{237}{figure.caption.109}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Sigmoid (\texttt  {sigmoid[x]}) and log-sigmoid (\texttt  {logsigmoid[x]})}{237}{subsection*.111}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The symmetric saturating linear with linear region of $[-1,1]$, a positive-negative variation of the saturating linear.}}{238}{figure.caption.110}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The sigmoidal function channel}}{238}{figure.caption.112}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The logarithmic sigmoidal function channel. Notice that the range of \texttt  {logsigmoid} is $[-\infty , 0]$, making it somewhat weird of a choice for a transfer function.}}{238}{figure.caption.113}\protected@file@percent }
\citation{*}
\bibdata{reference1}
\@writefile{toc}{\contentsline {subsection}{Hyperbolic tangent (\texttt  {tansig[x]})}{239}{subsection*.114}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The hyperbolic tangent transfer function channel.}}{239}{figure.caption.115}\protected@file@percent }
\bibcite{noauthor_bias-variance_nodate}{{1}{a}{{noa}}{{}}}
\bibcite{noauthor_neural_nodate}{{2}{b}{{noa}}{{}}}
\bibcite{noauthor_pdf_nodate-1}{{3}{c}{{noa}}{{}}}
\bibcite{unified_bias_composition}{{4}{}{{uni}}{{}}}
\bibcite{VeltenetalMathematicalModelling}{{5}{2024}{{Vel}}{{}}}
\bibcite{abhishek2019introductionconcentrationinequalities}{{6}{2019}{{Abhishek et~al.}}{{Abhishek, Maheshwari, and Gujar}}}
\bibcite{ANDRILLI20101}{{7}{2010}{{Andrilli and Hecker}}{{}}}
\bibcite{belkin_reconciling_2019}{{8}{2019{a}}{{Belkin et~al.}}{{Belkin, Hsu, Ma, and Mandal}}}
\bibcite{belkin_reconciling_2019-1}{{9}{2019{b}}{{Belkin et~al.}}{{Belkin, Hsu, Ma, and Mandal}}}
\bibcite{boucheron_concentration_2013}{{10}{2013}{{Boucheron et~al.}}{{Boucheron, Lugosi, and Massart}}}
\bibcite{bousquet2020theoryuniversallearning}{{11}{2020}{{Bousquet et~al.}}{{Bousquet, Hanneke, Moran, van Handel, and Yehudayoff}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{241}{chapter*.116}\protected@file@percent }
\bibcite{Briggs2014MachineE}{{12}{2014}{{Briggs}}{{}}}
\bibcite{Bronstein_2017}{{13}{2017}{{Bronstein et~al.}}{{Bronstein, Bruna, LeCun, Szlam, and Vandergheynst}}}
\bibcite{bronstein2021geometricdeeplearninggrids}{{14}{2021}{{Bronstein et~al.}}{{Bronstein, Bruna, Cohen, and Veličković}}}
\bibcite{brown2024biasvariance}{{15}{2024}{{Brown and Ali}}{{}}}
\bibcite{buschjager_generalized_2020}{{16}{2020{a}}{{Buschjäger et~al.}}{{Buschjäger, Pfahler, and Morik}}}
\bibcite{buschjager_generalized_2020-1}{{17}{2020{b}}{{Buschjäger et~al.}}{{Buschjäger, Pfahler, and Morik}}}
\bibcite{Cristianini2000AnIT}{{18}{2000}{{Cristianini and Shawe-Taylor}}{{}}}
\bibcite{d_ascoli_triple_2020}{{19}{2020}{{d'~Ascoli et~al.}}{{d'~Ascoli, Sagun, and Biroli}}}
\bibcite{davies_unifying_2023}{{20}{2023}{{Davies et~al.}}{{Davies, Langosco, and Krueger}}}
\bibcite{10.5555/2721661}{{21}{2014}{{Demuth et~al.}}{{Demuth, Beale, De~Jess, and Hagan}}}
\bibcite{Descartes1950-DESDOM}{{22}{1950}{{Descartes}}{{}}}
\bibcite{Domingos2000AUB}{{23}{2000{a}}{{Domingos}}{{}}}
\bibcite{domingos_unifeid_2000}{{24}{2000{b}}{{Domingos}}{{}}}
\bibcite{DreyfusImpasse1979}{{25}{1979}{{Dreyfus}}{{}}}
\bibcite{AIWashington}{{26}{2006}{{et~al.}}{{}}}
\bibcite{modelcomplex_exp}{{27}{}{{et~al.}}{{}}}
\bibcite{Scott_Fortmann_Bias}{{28}{2012}{{Fortmann}}{{}}}
\bibcite{6797087}{{29}{1992}{{Geman et~al.}}{{Geman, Bienenstock, and Doursat}}}
\bibcite{gerlach1872struktur}{{30}{1872}{{Gerlach}}{{}}}
\bibcite{Goel_2022}{{31}{2022}{{Goel}}{{}}}
\bibcite{goodfellow2016deep}{{32}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\bibcite{Grenander1952OnES}{{33}{1952}{{Grenander}}{{}}}
\bibcite{FrameGryzJarek}{{34}{2013}{{Gryz}}{{}}}
\bibcite{STL_Hajek_Maxim_2021}{{35}{2021}{{Hajek and Raginsky}}{{}}}
\bibcite{GRP_Hamilton}{{36}{}{{Hamilton}}{{}}}
\bibcite{hellstrom_bias_2020}{{37}{2020}{{Hellström et~al.}}{{Hellström, Dignum, and Bensch}}}
\bibcite{hu_model_2021}{{38}{2021}{{Hu et~al.}}{{Hu, Chu, Pei, Liu, and Bian}}}
\bibcite{gareth_james_introduction_2013}{{39}{2013}{{James et~al.}}{{James, Hastie, Tibshirani, and Witten}}}
\bibcite{1180370208}{{40}{2021}{{Kandel et~al.}}{{Kandel, Koester, Mack, and Siegelbaum}}}
\bibcite{10.5555/200548}{{41}{1994}{{Kearns and Vazirani}}{{}}}
\bibcite{khan_bayesian_2024}{{42}{2024}{{Khan and Rue}}{{}}}
\bibcite{lafon_understanding_2024}{{43}{2024}{{Lafon and Thomas}}{{}}}
\bibcite{liu2023understandingroleoptimizationdouble}{{44}{2023}{{Liu and Flanigan}}{{}}}
\bibcite{liu2025kankolmogorovarnoldnetworks}{{45}{2025}{{Liu et~al.}}{{Liu, Wang, Vaidya, Ruehle, Halverson, Soljačić, Hou, and Tegmark}}}
\bibcite{lopushanskyy2024graphneuralnetworksgraph}{{46}{2024}{{Lopushanskyy and Shi}}{{}}}
\bibcite{mcculloch_logical_1943}{{47}{1943}{{McCulloch and Pitts}}{{}}}
\bibcite{mehrabi_survey_2022}{{48}{2022}{{Mehrabi et~al.}}{{Mehrabi, Morstatter, Saxena, Lerman, and Galstyan}}}
\bibcite{articleMetaxiotis}{{49}{2000}{{Metaxiotis and Samouilidis}}{{}}}
\bibcite{10.5555/50066}{{50}{1988}{{Minsky and Papert}}{{}}}
\bibcite{neurondoctrinemishqat}{{51}{}{{Mishqat}}{{}}}
\bibcite{10.5555/2371238}{{52}{2012}{{Mohri et~al.}}{{Mohri, Rostamizadeh, and Talwalkar}}}
\bibcite{molavi_model_2024}{{53}{2024}{{Molavi et~al.}}{{Molavi, Tahbaz-Salehi, and Vedolin}}}
\bibcite{nakkiran_deep_2019}{{54}{2019}{{Nakkiran et~al.}}{{Nakkiran, Kaplun, Bansal, Yang, Barak, and Sutskever}}}
\bibcite{neal2019biasvariancetradeofftextbooksneed}{{55}{2019}{{Neal}}{{}}}
\bibcite{1056797NewellSimon}{{56}{1956}{{Newell and Simon}}{{}}}
\bibcite{olmin2024understandingepochwisedoubledescent}{{57}{2024}{{Olmin and Lindsten}}{{}}}
\bibcite{Oono2020Graph}{{58}{2020}{{Oono and Suzuki}}{{}}}
\bibcite{PfauBregmanDivergence}{{59}{2013}{{Pfau}}{{}}}
\bibcite{purves_neuroscience_2004}{{60}{2004}{{Purves et~al.}}{{Purves, Augustine, Fitzpatrick, Hall, LaMantia, McNamara, and Williams}}}
\bibcite{quetu_can_2023}{{61}{2023{a}}{{Quétu and Tartaglione}}{{}}}
\bibcite{quetu_can_2023-1}{{62}{2023{b}}{{Quétu and Tartaglione}}{{}}}
\bibcite{Rosenblatt1958ThePA}{{63}{1958}{{Rosenblatt}}{{}}}
\bibcite{rozo_cajal_2024}{{64}{2024}{{Rozo et~al.}}{{Rozo, Martínez-Gallego, and Rodríguez-Moreno}}}
\bibcite{10.5555/1671238}{{65}{2009}{{Russell and Norvig}}{{}}}
\bibcite{Scar04}{{66}{2009}{{Scarselli et~al.}}{{Scarselli, Gori, Tsoi, Hagenbuchner, and Monfardini}}}
\bibcite{schaeffer_double_2023}{{67}{2023}{{Schaeffer et~al.}}{{Schaeffer, Khona, Robertson, Boopathy, Pistunova, Rocks, Fiete, and Koyejo}}}
\bibcite{SeagerFrameAxiological}{{68}{2010s (or older}{{Seager}}{{)}}}
\bibcite{10.5555/2621980}{{69}{2014}{{Shalev-Shwartz and Ben-David}}{{}}}
\bibcite{sep-frame-problem}{{70}{2016}{{Shanahan}}{{}}}
\bibcite{sharma_bias-variance_2014}{{71}{2014}{{Sharma and Aiken}}{{}}}
\bibcite{shi2024homophilymodulatesdoubledescent}{{72}{2024}{{Shi et~al.}}{{Shi, Pan, Hu, and Dokmanić}}}
\bibcite{Sterkenburg_2024}{{73}{2024}{{Sterkenburg}}{{}}}
\bibcite{10.5555/2930837}{{74}{2015}{{Sugiyama}}{{}}}
\bibcite{tanis2024introductiongraphneuralnetworks}{{75}{2024}{{Tanis et~al.}}{{Tanis, Giannella, and Mariano}}}
\bibcite{10.1145/1968.1972}{{76}{1984}{{Valiant}}{{}}}
\bibcite{Vapnik1999-VAPTNO}{{77}{1999}{{Vapnik}}{{}}}
\bibcite{Veli_kovi__2023}{{78}{2023}{{Veličković}}{{}}}
\bibcite{WERKER198449}{{79}{1984}{{Werker and Tees}}{{}}}
\bibcite{yang_rethinking_2020}{{80}{2020}{{Yang et~al.}}{{Yang, Yu, You, Steinhardt, and Ma}}}
\bibcite{zhang2023divedeeplearning}{{81}{2023}{{Zhang et~al.}}{{Zhang, Lipton, Li, and Smola}}}
\bibstyle{plainnat}
\memsetcounter{lastsheet}{260}
\memsetcounter{lastpage}{246}
\gdef \@abspage@last{260}

\chapter{Classical connectionism theory}

Previous sections have been devoted to the writing and formulation of the naive, classical structure of models at best, and a very general question of the theory of actions (specifically, learning) on a specific hypothesis $h$ of a hypothesis set $\mathcal{H}$. One may then forward to ask about the intrinsic representation of the hypothesis class $\mathcal{H}$ for what it will actually be, similar to how we treated the representation scheme $\bm{\mathcal{R}}(\mathcal{C})$ of the concept class $\mathcal{C}$. One of the fundamental constructs that we can get aside from classical machine learning, in which the hypothesis class is arbitrary since there exists no general class, is the idea of a neural network architectural hypothesis class, or simply the \textbf{neural network} architecture. 

As it sounds, it is taken from the construction of the brain. Literature of this follows \cite{zhang2023divedeeplearning,10.5555/2721661} or any other literature sources that discuss the essence of the topic on itself. Do note that most of the time, they are more focused on the applicational side of it, often forgo the more strict, theoretical setting and general preset of the system itself, in a rather rough way. Also, personally, there exists no biological inspiration obligatory section either. 

\section{Biological inspiration}

Because it is a study of intelligence, we often find ourselves converging to the closet intelligent lifeform close by - which is us ourselves, and other species with developed brain region. For neuroscience, it has been widely received that the brain is constructed from many components, a lot of which comes around and connected together. \cite{mcculloch_logical_1943}, taking on this, devised the idea of meticulously replicate such operation of the brain, by defining the first ever logical neuron structure, called now the McCulloch-Pitts neuron. We would be giving a quick introduction to the brain itself, and some more important notes on how the neuron formalism is formed. For prerequisite, a bit about biology is required. Textbooks and resources that dive deeper into this problem is either \cite{1180370208} or \cite{purves_neuroscience_2004}, which will provide much more detail on the neuroscientifical development of the research on the brain. For now, let us see the structure of the brain by virtue of examplifying its representatives.

Informally, the brain encased the 'brain' - the nervous system in which defines its operation. This includes the central nervous system (CNS), and the peripheral nervous system (PNS). This is generally the conventional separation of the nervous system, as CNS includes the brain and spinal cord, while the peripheral nervous system consists of everything else. The CNS's responsibilities include receiving, processing, and responding to sensory information, while the peripheral, as its name, is similar to \textit{control relay} and sensory influences. 

The brain is divided into two \textit{hemispheres} (The reason is unknown for now, in terms of operational and evolutional accord), mainly for regional specialization. Between the two central hemispheres, they are connected by nerve bundles, in this case, is the thick band of fibers known as \textbf{corpus callosum}, consisting of about 200 million axons. The \textbf{axons} or \textbf{nerve fiber} is the long, slender projection of a nerve cell, or neuron, to different neurons and areas. So, think of it like a more extension cables from the transformer and generator. 

The \textbf{direction} between the 2 hemispherical connection is unknown, and can be either one-way, or two-way. But generally, we might want to take it as two-way, since it makes sense for when simultaneous tasks which requires multiple system on both sides to operates, remains so. Or rather, we can take it as the idea of \textbf{neural vacancy path}, that is, empty pathway that is one-directional specific in usage cases. More so like a conditional diode, depends on which way it was triggered first. But rather, it helps us to classify between the \textbf{communication directive} subjects, and \textbf{processing directive} subject of the brain.\index{neural vacancy path} 

\begin{note}[A note on the direction flow of nerve bundles]
    In the brain, a nerve bundle connects two regions and allows signals to travel between them.
 These connections can be one-way, where signals only travel in a single direction, or two-way, which allows communication both ways. Scientists discovered this a long time ago by dissecting the preserved brains of humans and other animals. Non-invasive MRI scans can tell us which brain regions have nerve bundles connecting them, but we can't know whether they are one or two-way connections.
 \vspace{2mm}

 Also, if they're one-way connections, we don't know the direction of movement. This is a limitation of current brain scan technology. Because scientists cannot tell the difference between a one or two-way connection in the brain, they usually assume all nerve bundles are two-way connections. This is a reasonable simplification in many cases, and \href{https://www.nature.com/articles/nrn3901}{has helped us understand a lot about the brain}.
\end{note}

During the process of constant communication, the left and right hemispheres are responsible for different behaviors, known as \textbf{brain lateralization}. This is the specialization we have talked about. However, we will not burden this section a description of the functions. \index{brain lateralization}

The bigger picture mentioned the brain connected by various sections, we noted that the brain is thoroughly connected by millions, hundred of millions of axons. One then might ask where and what that those axons were connected to. Most of the time, we recognized that they are connected to the brain's components called \textbf{neuron} - the small central processing unit of the brain itself. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{img/brainneuron1.png}
    \caption{The simplistic, schematic illustration of the structure of the biological neuron.}
\end{figure}

The brain consists of a large number (approximately $10^{11}$) of highly connected neurons. For our purpose, we simplify them to mostly three principal components, beside its life support: the \textbf{dendrites}\index{dendrites}, the cell body and the \textbf{axon}\index{axon}. The dendrites are tree-like receptive networks of nerve fibres that carry electrical signals into the cell body. The cell model effectively sums and thresholds these incoming signals. The axon is simply, as we have said, the cord connecting other neurons to it. The point of contact between an axon of one cell and a dendrite of another cell is then called a \textbf{synapse}\index{synapse}. It is the arrangement of neurons and the strengths of individual synapses, determined by a complex chemical process, that establishes the function of the biological neural network - though even by then, it is a gross simplification of the actual process - mostly based on empirical evidences. 

Aside from neuron, of the \textbf{cellular neurology} point of view, there exists also the \textbf{glia}, or \textbf{neuroglia} \index{neuroglia}for the full name, which serves as the supporting cells for the operation of the main neurons' system. Specifically, the neuroglia should be emphasized to be rather inert - it does not align, or rather, can be classified as an operating unit in the brain, with respect to the well-known electrically excitable process that its brother neuron possesses. Indeed, because of such, there are many definitions in which neuroglia can take from, most of which are rather diluting, hence hitherto there are no agreed upon definition. In the above statement, we note that neuroglia as the supportive cells of neurons, but many exists to classify it by their process branching and delicate morphology, or, as mentioned, electrically inert components. As a result, 'neuroglia' has been come the generalized term that covers cells with different origins, morphology, physiological properties and functional specialization \textit{aside from} the nervous cells of the brain. Such can be said of the uncertain analysis of neuroglia to the operation process and the long, complex chain of thoughts and functioning scheme of the host that it resides in, for whether the neuroglia participate in any incumbant roles throughout its working space. This is perhaps one of the issues with neuroglia researches, though it is not to say many attempts has been made trying to understand it, but rather the underrated position of the neuroglia to the other part of the brain itself. So, this much remains as a mystery. 

By itself, the brain's neuron and its neural structure is insanely complex. By time and birth, some of the neural structure is defined at birth. We don't know if this is encoded into itself by genes, but most likely so from biological evolutions itself. Other parts are developed through the dynamic action, often interpreted as learning (which is why we have the theory of learning), as new connections are made and others waste away. This development is most noticeable in the early stages of life. This is present in almost all developed neural structure of any given brain of any species. For example, it has been shown that if a young cat is denited use of one eye during a critical window of time, it will never develop normal vision in that eye. Linguists also have discovered that infants over six months of age can no longer discriminate certain speech sounds, unless they were exposed to them earlier in their life \cite{WERKER198449}. Somehow, it is also pretty vindicative to believe that the brain and all other functional components have a certain development timeframe deeply encoded in its biological encoding itself. Behaviourally, we can also interject that without pressure (like the fact that the cat must see, and must walk, so that it must move its legs and eyes), many functions would cease to be available. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{img/SantiagoRam처nyCajalNetwork.png}
    \caption{An illustration of Santiago Ram처n y Cajal on the structure and design of a biological brain network. Many of these was made during his career.}
\end{figure}

Neural structures continue to change throughout life. These later changes tend to consist mainly of strengthning or weakening of synaptic junctions. For instance, it is belived, by 2000, that new memories are formed by modification of these synaptic strengths. However, this also posits the question of if the structure is static after a while - no more neurons constructed, then why would it be possible that, classical theory dictated, and our later on model will provide, that the neuron network of the same topology can give many memories at once? This questions, among others, require extensive studies and deep dive into the field of brain study. 

Adding to the complexity, studying intensively in neuroscience will even separate the description of neuron further. When neuroscience was formed, and was developed, early in the nineteenth century the cell was recognized, only by then, as the fundamental unit of all living organisms. However, it was not until well into the twentieth century, that neuroscientists agreed that nervous tissue, like all other organs, is made up of these fundamental units. This would then bring out a surprising result by itself from the genetic side: of the 35,000 genes in human genome, a majority are expressed in the developing and adult brain; same is in other animals; and most of all, \textit{very few genes} are \textit{uniquely expressed} in neurons, indicating that there exists a very well general structure for the building blocks of human. One then can be more surprised: why didn't they discover it sooner? The major problem and problem was that the first generation of "modern" neurobiologists in the nineteenth century had difficulty resolving the unitary nature of nerve cells with the microscopes and cell staining techniques that were then available. By that, we mean that "it's all because of the experimental system itself.". This inadequacy of observing the structure of neuron, was further exacerbated because of the ostensively, extraordinarily complex shapes and extensive branches of individual nerve cells, which further obscured their resemblance to the geometrically simpler cells of other tissues. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{img/overwhelminglycomplexshit.png}
    \caption{Examples of the rich variety of nerve cell morphologies found in the human nervous system. Tracings are from actual nerve cells stained by impregnation with silver salts (the socalled Golgi technique the method used in the classical studies of Golgi and Cajal). Asterisks indicate that the axon runs on much farther than shown. Note that some cells, like the retinal bipolar cell, have a very short axon, and that others, like the retinal amacrine cell, have no axon at all. The drawings are not all at the same scale. Some more details about the jargon is the \textit{retinal bipolar cells}, which are neurons that connect the outer retina to the inner retina, for processing layer (or projection neurons, where all information are relayed from this connection.); the \textit{retinal ganglion cell, amacrine cells} are the same visual processing unit; Cerebellar Purkinje cells (a type of GABAergic neurons) uniquely determined for cerebella cortex (for processing large data, and coordinating functions like cognition and emotions.). Reused from \cite{purves_neuroscience_2004}.}
\end{figure}

This then prompted, not surprisingly, the two rather classically famous approach to understanding the intricate structure that was observed. The first to arrive is the \textbf{Reticular Theory}\index{Reticular Theory} of neurons, by prominent of Golgi and others like Joseph von Gerlach. Such is said about Reticular Theory by Golgi in his Nobel Prize for Physiology or Medicine (1906) that the axons physically join one nerve cell to another. By analogy, that is like saying that the brain is coherently connected, joined together like an electricity distribution network. For Gerlach, he even wrote a two-page article titled "Ueber die Structur der grauen Substanz des menschlichen Grosshirns. Vorl채ufige Mitheilung" \cite{gerlach1872struktur} in which the sentences ended with `[these cells] are interconnected with each other as well as connected with the radial bundle, whereby a coarsely meshed network of medullated fibres is produced which can already be seen at 60 times magnification'. This theory eventually, though, fell from favor and was replaced by what came to be known as the "neuron doctrine", championed by Santiago Ram처n y Cajal, a Spanish neuroanatomist, and Charles Sherrington, a British physiologist. This theory insists on the otherwise different interpretation - the brain is not continuous, and is rather composed of \textit{independent cells} and components. \index{Neural Doctrine} More than ever, it also gives us some very beautiful illustration of Cajal himself. 

The contrasting views represented by Golgi and Cajal occasioned a spirited debate in the early twentieth century, that set the course of modern neuroscience. At the end of the day, however, it seems like the modern world of neuroscience has chosen Cajal because of the prominently accurate expression of Cajal, and supported by immense experimental result - particularly after the invention of electron microscopy in the 1950s. Out of this debate, and a lifelong endeavour, is the tuple of neuron-neuroglia as we have been discussing of. 

We would be wise to intercept this complexity with a specific modelling, and to use whatever knowledge attainable of the moment rather than waiting for neuroscientist to fully discover the brain - at that point, there is not much to be done anymore (others than copying and replicating, that is). Because it is so complex, artificial neural networks donot approach the complexity of the brain by itself. Rather, we restrict ourselves to a very simplified notion of the neuron. Nevertheless, two key similarities between biological and artificial neural networks can be founded. First, the building blocks of both networks are simple computational devices - note that this is a \textbf{serious, gross simplification from both side} of the equation - that are highly connected. Second, the connections determine the function of the network. Then, particular configuration of the network will be much better utilized in some tasks, and less of others. This is a dynamic of functions that is perhaps also presented in biological networks. Also, we will also remove the neuroglia of the equation in the subsequent model that will be presented. Such is to say, we are not replicating the neural system by everything, but rather, focusing on the not-so-inert part of it.

With this, we are now ready to begin our model of neuron. We will do it step by step. Not wasting anything in between, that is. But first, we need to know what does our neuron do, in the most general way. 

\section{The neuron model}

Because, generally, we have discussed and formalize somewhat our mathematical modelling setting into the 3-tuple $(S,Q,M)$, it would be a loss of rigours if we are not to treat the neuron in a structural way. In such, we will also absolve certain ambiguity, if able.  

The system $S$ in concerned of the neuron model is perhaps different from what we will be having in general. Normally, we will consider the system in which only the object of interest. In such sense, our structure will contain the following: The model object's components, or \textbf{atoms} $\{n\}$, and the larger construction that is our model, $N[\{n_{i}\mid k\}]$, for any $k$ configuration that is for now arbitrary. This will be good for the time being, however, later on, if we are to expand it into a larger, bigger system in which multiple 'models' are made, then we will have to find ourselves another interpretation. 

In such case, there exist two approaches. One can approach the problem by extending the model into not just a neuron, but a bigger network of neurons, yet so forth being a single neuron in interpretation. That is, there now another configuration $k'$ that gives a comparatively \textit{recursive definition} of the neuron: a network of neuron acts like a neuron, containing inside it neurons of smaller size. This means then a "neural network" is essentially the model $N[\{n_{i}\mid k',k\}]$ such that each $n_{i}\to k'$ configuration is a neuron, and under them are the configurations $k$ of the neuron class. This interpretation is rather suffice, but again, it considers a fairly strict amount of construction, and there is also the problem with interpreting the recursion section, too. Instead, what we can do is to simply extend the system. Now, the object of the system will be bounded above. That is, the system $S$ now contains, for example, the following objects: 
\begin{equation}
    \begin{split}
        S &=  \{n_{i}\} \\ 
        &\cup  \{N_{k}\} = \{n_{i}\mid k \in \mathcal{K} = \mathcal{K}^{1}, r\in \mathcal{R}\}\\
        &\cup \{\mathcal{N}\} = \{ N\mid k' \in \mathcal{K}' = \mathcal{K}^{(2)} \} 
    \end{split}
\end{equation}

Note that this is not the current notation of choice, only for illustrative purpose, so we will be able to forgive some of the lack of coherent notation like $n,N,\mathcal{N}$. For each level of the neural network structure that will be eventually constructed, we will have each individual component set. Using a rather naive notion, we have then implicitly strict our model, in which we will discuss in more detail in a bit more time. It is also notably interesting of the implication of the $\mathcal{K}^{(i)}$ ordering model can be. In fact, it can provide us with an even more compact, and abstracting level of neural processing unit, though we will not discuss such for now. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{img/abstractionpps.png}
    \caption{An illustrative example of the abstraction and categorization by 'size' of different components and constructs in the neuron model. By the order of abstraction $k$, we assign a notion of size on different neural structure, by increasing complexity, and backward compatibility (described to be composed of previously defined objects). The first two stage for $k=1,2$ includes the standard basis components $\{n_{0,i}\}$ and the standard neuron class $N_{0}$, respectively.}
\end{figure}

Now, for the question $Q$. What is it that the questions we have when we are constructing this model of neuron? Normally, the question would be rather on the extreme: we want to \textit{reconstruct the neuron}, or rather, making a unit that functions in the same way, or abiding its principles. In doing such definition, we will be able to rule out certain factors, and perhaps focus on the state variables system instead. 

By this, we assume no physical realization. Hence, factors that rely on the physical interpretation and phenomena - for example, the delays inbetween signal transmission - we then assume our data is instantaneous. The forming of axons and synapses will also not be included, as we might as well work with a static wiring scenario instead. Simplify even more, and we get to the point where we will only extract the supposed fundamental unit of operating, that is, turning the neuron into exactly an input-output unit. All construction of variations of this type of neural construct is then called the \textbf{neuron class} (classical) in which connectionist builds their neuron. Denoted as $N$, the neuron class is constructed of three fundamental components as $(I(p), \Sigma, f)$, where $I$ handles the input into the neuron, $\Sigma$ preprocess the input into some forms or another, and $f$ regulates the internal mechanism of output-transimission of the neuron - in a somewhat ambiguous term, regulate what the neuron is designed to "think" given specific input and its own interpretation as $f$. If you see others, more advanced and often messy construction of a neuron, then it is because they have added semantics onto it, or rather, the supporting and outer influencing components. However, the standard issued compartments are the same, and hence, we would treat this as the base model for our neuron unit.

Each operation in the neuron model, at least for the standard basis, serves a different purpose. The input $I$ is there to handle the input, by symbolically giving each signal or channel of a specific elementary configuration, called \textbf{weights} $w$. This will determine the relative "importance" of a given input, or by scaling up and down the channel's information inward. Numerically, it controls how the prelimiary processing or dependency of inputs are observed to be configured in the objective concept that is required to be mimicked. For example, if the objective concept is something like $3x_1 + 4x_2 - 1/5 x_3$, we would expect the preliminary process to handle the factor $(3,4,1/5)$ to be replicated by behaviours of $x_i$. $\Sigma$ on the other hand, provides the $+$ operation inside. Often, we use addition or for a vector representation of all input $\mathbf{x}\in \mathbf{X}$, it is the dot product. But generally, it is defined for all generalized composing operation $\Sigma= \bigoplus_{i=1}^{n}w_i n_i$. And finally, as we may have been familiar, is the interpreter of the neuron, the transfer function $f$. Though, arguably, the transfer function is classically defined only for it to be able to let the neuron be nonlinear, with respect to the space of all numerical representation. 

With this, we are able to define the first definition on the neuron model. This is a preliminary definition, since we will add things in later on.

\begin{definition}[Neuron model,  Preliminary definition]
    The neuron model conceptually can be encapsulated into the categorization of all \textbf{neuron class} $N$ with the \textbf{standard basis} denoted by $N_{0}$. The standard basis is then consists of the tuple $(I,\Sigma, f)$, where $I$ denotes the process operates on input form which denoted $p$, $\Sigma$ is the input internal process - most prominent in case of multiple discrete input channel present (essentially helps to organize the input interface), and $f$ is the \textbf{interpretation output} of the model. 
\end{definition}

It is good to observe that the neuron as a unit is somewhat very similar to how we observe the black-box model of mathematical modelling, for a given problem. Hence, it is sufficed to say, generally, that in some ways or another, that the neural unit is actually approximating the supposed internal state of a black-box system, by presupposing certain simplification or empirical generalization of the observed information. This is often not guaranteed to be similar to the actual black box, but rather of its own interpretation unit, to approximate it with a pre-supposed internal mechanics instead. One could then ask though, of the extended problem to this conception of neural unit - what would then be the expression for the \textbf{internal system of a neural network} (more than one neuron)? We would do this in sequence, so let's hope that we will touch upon this. 


Lastly, to finalize, we ought to give ourselves the plenty (mathematical) statement in consideration of the system in which our neuron will be defined of their subjects and functions. Those will hopefully, eventually lay out the correct assumptions that we took, figuratively, and to prevent further ambiguity (in the case where everyone, and anyone get different reactions or formulations). In essence, our construction forgo the following assumptions for the statements $M$:

\begin{itemize}[itemsep=1pt, topsep=3pt,leftmargin=4pt]
    \item[(+)] The flow of information and operation is \textit{one-dimensional, single-directed}. That is, every operation follows the schema recognized by the input-output model, such that any open interface or exposed structure must abide the sequential and single-directed flow of process, for all components in a neuron class. This then defines a \textbf{'heliocentric' topology} \index{heliocentric topology} on the neuron class, denoted by $C$ which organize the flow of process. Then, single-directed means that $C$ is minimally described by a vector $\vec{d}$, such that if each neuron is represented per specification, into a directed graph (either equipped with an embedding space or not), then the component's direction vector $\vec{c}_{i}\in C$ , must satisfy $\langle \vec{d},\vec{c}_{i}\rangle \geq 0$. This notion wil have to be expanded later on, as we will see why it is perhaps more important than not. In fact, I am racking my brain to think of the case when one dimensional, without single-directed description would be. This notion also generally can be applied to larger network as well. 
    \item[(+)] Almost all physical realization of the neuron is removed in the modelling. That is, there exists no synapses and axons, replaced by the abstract input-output - we assume no failure of communication. Furthermore, we assume that each neuron can handle infinite amount of data, given certain representation of said data channel, and output of the same amount. If not explicitly stated, we also assume that the channel capacity between each connection is negligible, and always infinite. Numerically, all neuron also has infinite numerical representation range, at least when it comes to the real number field $\mathbb{R}$. 
    \item[(+)] All neuron class can be subsequently reduced to the standard basis neuron class $N_{0}$. 
    \item[(+)] The input section $I$ only process data by packaging each input channel with a modifiable weight $w$, or the importance measure, and nothing more. 
    \item[(+)] All information or materials assigned in the operating and living space of the model is numerical, perhaps. As such, we might want to insist on a clear \textit{representation scheme}, and a embedded structure within all numerical system used to represent it. 
    \item[(+)] Each neuron has two types of parameters: the macroscopic parameters that define its structure, called \textbf{hyperparameter}, and the inner mechanism-specific parameters, called the \textit{systemic parameters} that is intrinsic of the inner configuration and operation. For our theoretical treatment and applications of the model, our model assumes \textbf{static construction} but \textbf{dynamic mechanics} for said construction. The reverse is noteworthy of being analyzed, and this criteria in general is an interesting notion. 
    \item[(+)] A consequence of the single-directed flow is that one can form a neuron loop with two or more neuron together. For a network of connected neuron, we said that it is an \textbf{isolated}, or contained network if no connection is headless - not connected to any of the given neuron. 
    \item[(+)] A neuron can perform self-loop - feeding itself of its own output. This scales up for network as well.  
    \item[(+)] Correction within connections of neuron is negligible and is almost non-existence in context. If there exists noise or unwanted information, then it will almost be presented in the input observations and information - any external sources. 
\end{itemize}

Each neuron can also be defined by either design, or by operation, to be independent of each other. This is often conducted by defining the relative dependency, given the assumption in design of being single-directed, most representable by the notion of \textbf{layer}\index{layer}, denoted by $\mathcal{L}^{(i)}$. A layer is, loosely speaking, an ensemble of neuron units, all of which is arranged in parallel, with equal processing order, that is, they operate sequentially parallel as a cluster on their own. Then, each layer defines the relative dependency to the previous layer, if there are any, and hence, a neuron only depends on the behaviour feed of neurons in previous layers. For a neuron $n[i]\in \mathcal{L}^{(j)}$, however, it can also be designed such that inhibitory neuron in $\mathcal{L}^{(j-1)}$ does not affect its operation or signals of other neurons in operation. For example, that is why a lot of typical construction of neuron use $\Sigma = \sum_{i=1}^{n} w_{i}p_{i}[R]$ for input sequence $p[R]$ of range $R$, such that if one neuron is inhibitory ($=0$), then others are not affected. This is perhaps trivial, and should not have been mentioned, but I mention it anyway. 

Using the better, well-founded notion for $(S,Q,M)$, we then define a more conclusive definition of the conceptual neuron model. 
\begin{definition}[Neuron model, neuron class]
    The neuron model conceptually can be encapsulated into the categorization of all \textbf{neuron class} $\mathcal{N}_{k_{i}}^{(i)}$\footnote{This description is perhaps incomplete, but we will use it throughout our formation as it is. the suffix $k$ relies on the arbitrary meaning of a \textit{configuration space}, hence $k_i$ is all arbitrary configurations possible for structure of order $i$.}, for $i=1$, specified by two descriptions for any neuron $n\in \mathcal{N}_{k_{i}}^{(i)}$: An quantized, 'parameter(-ized)' descriptions contains all variables or parameters that define the \textbf{represented mass} of the model, denoted $N$, and the operational description contains, for example, rules, flows, cases, orders, functionals, special values, denoted by $\mathcal{M}$. We can also call the neuron class as the \textbf{hypothesis class}, for $h\in \mathcal{H}$ of a given description.
\end{definition}

An interesting question (perhaps can be said to be fairly long, and an \textit{interesting side tangent}) arises when we state out those question by ourselves, and is perhaps more importance in the sense of information theory and perhaps, quantum mechanical interpretation. \footnote{A trivial note. In the process of neuron functions, there will always be information down scaling and dimensional transformation. Information losses and reinterpretability is questioned, as always, but might be redundant as it is. }
\begin{question}
    How is information, or \textbf{resources per matters} are preserved or transmitted in an artificial neuron $a$ of a given neuron class of both standard basis or more? Are all information destroyed figuratively, if one assume no knowledge from the external modifier side (in a typically learning process, one requires a supervisor with full exposure to the internal mechanics of the neuron model - or generally the hypothesis). Given two neuron acting on the same scenario, but with diverted process, can one revert the information to retrieve the opposite reversed neuron respectively, in which we call the standard one the \textit{encoder}, and the opposite the \textit{decoder}? What is their topology?
\end{question}
For this question, we have to deal with a lot of things more before the experimental setting can be structured to test it. Another point to note is that usually, one can treat the neuron component $f$ as the neuron's intrinsic interpretation of the encoding space. What does the encoding space means will be further defined and explored, but for now, you can picture it as its interpretation in the numerical encoding of the world and observations thereof. The question above indicted the issues toward the lack of analysis in such aspect, however, we would like to present interesting notions on said view, for example, \cite{liu2025kankolmogorovarnoldnetworks} with their \textbf{Kolmogorov-Arnold Networks (KAN)}. We leave this for now in favour of the foundational assembly of our model, to be discussed in later sections.  

\section{Notation}
Before we construct neurons and their individual components, we would have to select and systemize our choices of the notation specifically. We make deferences of the neuron class, such that all neuronal architecture class is denoted by $\mathcal{N}_{i}^{(p)}$, for any variation $p$ of the neuron class of level $i$ in the relative scale, for $i\geq k$. A specific \textit{network construction} of the neuron, is then called neural network, denoted by $\mathfrak{N}$. Distinguishing between neural networks altogether would be used of varied subscripts and superscripts, as there exists no strict rules on them. Each \textbf{neuronal unit} (or just neuron instance) is denoted by $N\in \mathcal{N}_{i}^{(p)}$. Component-wise, we can also write $\mathfrak{N}=\prod_{i< k} \mathcal{N}_{i}$ by the Cartesian product on the neuron set (we typically use neuron set and class in conjunction with each other anyway) to represents different configuration possible, or at least the space of which the neural network takes from. The component of individual neuron is then denoted generally by $q_{j}$ for $j$ the index for all $r$ components of a neuron; $r$ is also available as specification from the neuron class, however, subsets of each neuron class might have just different $r$. We will proceed with the above notation, and any given improvements or changes in notations will be specific instead. 

We are now then ready to introduce to the general notion and construction of the very first object, the neuron. 
\section{General neuron unit class}

As we might have observed, neuron has its own familiar properties and characteristics that defines the name `neuron'. We then might as well classify the neuron in an operational sense - purely as a working, functional mechanics. Then, a neuron $x\in \mathcal{N}$ of any class will have to have the following component classifications as its minimal requirement to be classified as such: 
\begin{enumerate}[topsep=1pt,itemsep=0.5pt,leftmargin=18pt]
    \item One external state unit, or \textbf{input unit} $I$. 
    \item One internal state and action units, or \textbf{mechanical unit} $M$. 
    \item One external action unit, or \textbf{output unit} $O$. 
\end{enumerate}
We can define this formally as a definition, though it does not change much from the original presumption rather than stating the already established notion. However, we will then call such as a framework \index{Minimal framework}.
\begin{definition}[Minimal framework]
    Let $x\in \mathcal{N}_{i}$ be any neuron unit of class $i$th. Then, it must satisfy the minimal framework requirement, such that $x\equiv (I,M,O)$ for input unit $I$, mechanical unit $M$, and output unit $O$. Let $(i,j,k)$ for $i,j,k\in \{|I|\},\{|O|\},\{|O|\}\subset \mathbb{N}$, then if $(i,j,k)=(1,1,1)$, then we call $x$ a \textbf{standard neuron}, denoted $x_{S}$ or $\phi_{S}$. 
\end{definition}
With this condition, any construct $x$ of this type would be called a neuron unit. There is simply no configuration specified, so $x$ can belong to any $i$th class. This is illustrated as in Figure~\ref{fig:nn1}. Every member of a class would then be concerned of largely those objects that can be classified as such. 
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.6\textwidth]{img/nn1.png}
    \caption{The standard minimal configuration of any neuron $x\in \mathcal{N}_{i}$. We denote $p$, $q$ for particular neuron input and output sequences.}
    \label{fig:nn1}
\end{figure}

Even though we insisted on the components, many times they can be missing from the neuron yet would still be called as such. In such "edge case", we can employ the notion of inhibition or blocking to represent, or at least interpret the absence of such action as to be blocked, rather than the missing of such component. Therefore, a neuron without $I$ is called an \textbf{isolated (neuron) unit}, a neuron without $O$ is called an \textbf{inhibitory (neuron) unit}, and a neuron without $M$ mutation is called a \textbf{dummy (neuron) unit}. More importantly, dummy units will be used in plenty illustrations and formation to classify typical linear behaviour, unchanged instructions, or placeholders. 

Furthermore, as we have been seeing from the formulation, it is also of interest to know why we implicitly want to have only one unit for each type of components. Thereby, we would also define the component classes. Hence, there exists the \textbf{input (unit) class}, the \textbf{output (unit) class} and the \textbf{internal (unit) class}. And as the definition above hold, the reason for minimal class to be satisfied is not special at all. Well, at all. It simply is to restrict the component class, and to somewhat prevent unnecessary constructions that would lead to overcomplication later, for example, by not examining standard component, the dilemma between many-input and single-input neuron will get far more complex. Mentioning this, and countering this by force at hand is perhaps more suited as for now, so that we will not encounter the same later on. And it also applies with our view on constructing everything in a similar way computers and electrical components constructs larger units. Then, let's see how we can make use of the standard neuron first, by introducing the first class - the class \textbf{$\mathcal{N}_{0}$ simplex}. 
\section{Class $\mathcal{N}_{0}$ simplex}
The first neuron structure is the single-input, single-output, minimal neuron construct. A neuron $N\in \mathcal{N}_{0}$ considers all special neuron construction such that $\mathcal{N}_{0}=\{I,M,O\}$, where $I$ represents the input module (and its processor), $M$ is the inner structure of the neuron, and $O$ represents the output unit of it. The first neuron of the class $\mathcal{N}_{0}$ is called the standard neuron, historically introduced throughout by \cite{mcculloch_logical_1943,nakkiran_deep_2019,goodfellow2016deep}. 
\begin{definition}[Standard neuron]
    A neuron unit $x\in \mathcal{N}$ belongs to class $\mathcal{N}_{0}$ and is called a \textbf{standard neuron} if $\lvert (I,M,O)[x]\rvert = (1,1,1)$ and is expressed by \begin{equation}
        (I,M,O)[x] = q = \sigma_{M}(w\cdot p + b)
    \end{equation}
    For $w,p\in I, q\in O, \sigma, b \in M$, for $\sigma: I\to O$ a function. If $\sigma$ is linear, then we say $x$ is a \textbf{linear unit}. 
\end{definition}
Using this definition, we have constructed a standard neuron without any single component added outside the categorization above. While we have been saying arbitrarily placeholder for the components, it's then we have to clarify the options and specification for each component.